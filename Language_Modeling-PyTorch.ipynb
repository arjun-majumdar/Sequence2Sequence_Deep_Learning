{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c11464-e3a5-4228-8ce2-dc8a13fda32a",
   "metadata": {},
   "source": [
    "# Language Modeling: PyTorch\n",
    "\n",
    "[Reference](https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be117d2-8187-4864-94ce-80d733af3fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca344a0e-54ef-4cf0-97bc-9b561d50d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/anaconda3/envs/pytorch-gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, copy, pickle, string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b25a3-5b68-46a3-a0b0-a8fb31e2c453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73e8e3-522b-48c2-994a-6911d578b2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06e271c-b31c-47b9-842f-d492b10df2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774a82ca-9e5b-480a-9457-5481fda30a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU(s) available = 1\n",
      "Current GPU: 0\n",
      "Current GPU name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# Check if there are multiple devices (i.e., GPU cards)-\n",
    "print(f\"Number of GPU(s) available = {torch.cuda.device_count()}\")\n",
    "\n",
    "# Which GPU Is The Current GPU?\n",
    "# print(f\"current GPU: {torch.cuda.current_device()}\")\n",
    "\n",
    "# Get the name of the current GPU-\n",
    "# print(f\"Current GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "# Is PyTorch using a GPU?\n",
    "# print(f\"Is PyTorch using a GPU? {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"Current GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"PyTorch does not have access to GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25ac339-0d8f-4567-bb44-4a745d7a4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device is cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration-\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Available device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b8947-aeca-4a5e-af49-5a11db8ef728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da46b9b-f105-4362-892d-91d20e2425b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1ff53d-f9a6-4a16-8d1c-710734b0f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyper-parameters\n",
    "batch_size = 256\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0af713-a7db-4740-8d6a-58015f408485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffa967-d41b-4b0d-a92c-901584a5fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbb95c0d-91dd-4f73-9c9e-1821b19471f1",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "- ```Dataset``` class inherits from the PyTorch's ```torch.utils.data.Dataset``` class and defines two important methods ```__len__``` and ```__getitem__```.\n",
    "\n",
    "- ```load_words()``` function loads the dataset. Unique words are calculated in the dataset to define the size of the network's vocabulary and embedding size. ```index_to_word()``` and ```word_to_index()``` converts words to number indexes and visa versa.\n",
    "\n",
    "- This is part of the process is known as __tokenization__. In the future, ```torchtext``` team plan to improve this part, but they are re-designing it and the new API is too unstable for this tutorial as of today.\n",
    "\n",
    "[PyTorch data loading tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ae186-b83a-4510-8cf4-0ec14e9075e0",
   "metadata": {},
   "source": [
    "#### Shakespeare text file is large and causes CUDA OOM error! So, a much smaller text corpus is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3bb81-5949-4784-9f8f-afbde5d32da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Read in txt file containing dataset-\n",
    "with open('shakespeare_text.txt', 'r', encoding = 'utf-8') as file:\n",
    "    file = file.readlines()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b6ef2-6380-4df7-9feb-3919025b9b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"number of lines in dataset = {len(file)}\")\n",
    "# number of lines in dataset = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadc4de-dc39-4820-bd7a-c410120e5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First two lines-\n",
    "# file[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bcdbb-0d4d-45eb-8cce-b0ed352c58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace newline with <EOS> token-\n",
    "# file[0].replace(\"\\r\", \"<EOS>\").replace(\"\\n\", \"<EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012cb16-206d-4ffd-8c48-b740688d434d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f472ed27-e554-4795-858a-33b9156f7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, sequence_length\n",
    "    ):\n",
    "        # self.file_corpus = file_corpus\n",
    "        self.sequence_length = sequence_length\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        # Convert number indices to words-\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        \n",
    "        # Convert word to number indices-\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv('reddit_cleanjokes.csv')\n",
    "        text = train_df['Joke'].str.cat(sep = ' ')\n",
    "        return text.split(' ')\n",
    "        '''\n",
    "        text = \"\".join(v for v in self.file_corpus if v not in string.punctuation).lower()\n",
    "        text = text.encode(\"utf-8\").decode(\"ascii\", \"ignore\")\n",
    "        return text.split(' ')\n",
    "        '''\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(\n",
    "            word_counts, key = word_counts.get,\n",
    "            reverse = True\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.words_indexes) - self.args.sequence_length\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index : index + self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1 : index + self.sequence_length + 1]),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41408f8-100f-47bf-b662-551c867dfcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10b157-d99c-4101-8402-ac20ecbd7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute maximum sequence length for a given text corpus-\n",
    "# max_sequence_len = max([len(x) for x in file])\n",
    "# print(f\"maximum sequence length in the given training text corpus = {max_sequence_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26b76ac-680b-4f11-b424-3131b9825ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using low sequence length due to CUDA OOM error problems-\n",
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb9cf42-3a1b-45e5-b0cf-2b356b58bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get torch dataset-\n",
    "dataset = Dataset(sequence_length = sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7db0043-6d32-403f-bd3d-d80a5431dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in dataset = 23914\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of words in dataset = {len(dataset.words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c5fed-a915-46c5-b209-c860a4277f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49b7dcf-4dcb-4a8c-9b70-9e0f0859d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader-\n",
    "dataloader = DataLoader(\n",
    "    dataset = dataset, batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b494d26f-bde7-4ea8-814b-48606b8bcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1a9638-22c6-4a24-96f3-3ad3a62160ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([256, 10]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), x[0].shape, x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64f57504-35b0-4f11-92c7-01940ebb7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4340b-d194-4a3e-8387-93bbf1aadc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9277bf5-45c5-43a5-ac71-0e9fbe756ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec6e5232-e0e2-4467-b178-d398d17af0bd",
   "metadata": {},
   "source": [
    "### Define _Language Modeling Seq2Seq_ architecture\n",
    "\n",
    "This is a standard looking PyTorch model.\n",
    "\n",
    "- __```Embedding``` layer converts word indexes to word vectors__.\n",
    "\n",
    "- LSTM is the main learnable part of the network - PyTorch implementation has the gating mechanisms implemented inside the LSTM cell that can learn long sequences of data.\n",
    "\n",
    "- RNNs and LSTMs have extra state information they carry between training episodes.\n",
    "\n",
    "- ```forward()``` function has a ```prev_state``` argument. This state is kept outside the model and passed manually.\n",
    "\n",
    "- It also has ```init_state()``` function. Calling this at the start of every epoch to initializes the right shape of the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad767cd-e161-4c42-901f-718f20ae6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, dataset,\n",
    "        lstm_size = 128, embedding_dim = 128,\n",
    "        num_layers = 3\n",
    "    ):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Count number of unique words in vocabulary/dictionary-\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings = n_vocab,\n",
    "            embedding_dim = self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = self.lstm_size,\n",
    "            hidden_size = self.lstm_size,\n",
    "            num_layers = self.num_layers,\n",
    "            dropout = 0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features = self.lstm_size, out_features = n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (\n",
    "            torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "            torch.zeros(self.num_layers, sequence_length, self.lstm_size)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b7364-0874-4095-8908-01ae2dd100d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da9e4b6-0587-46d0-9ea2-ded97a10b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM model-\n",
    "model = LSTM_Model(\n",
    "    dataset = dataset, lstm_size = 128,\n",
    "    embedding_dim = 128, num_layers = 2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259560b0-2e44-43a5-a63a-7a8b343995a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95edee25-af33-42c6-9d00-fd8abdd38094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight has dimension = (6925, 128)\n",
      "lstm.weight_ih_l0 has dimension = (512, 128)\n",
      "lstm.weight_hh_l0 has dimension = (512, 128)\n",
      "lstm.bias_ih_l0 has dimension = (512,)\n",
      "lstm.bias_hh_l0 has dimension = (512,)\n",
      "lstm.weight_ih_l1 has dimension = (512, 128)\n",
      "lstm.weight_hh_l1 has dimension = (512, 128)\n",
      "lstm.bias_ih_l1 has dimension = (512,)\n",
      "lstm.bias_hh_l1 has dimension = (512,)\n",
      "fc.weight has dimension = (6925, 128)\n",
      "fc.bias has dimension = (6925,)\n"
     ]
    }
   ],
   "source": [
    "tot_params = 0\n",
    "\n",
    "# Print layer names-\n",
    "for layer in model.state_dict().keys():\n",
    "    print(f\"{layer} has dimension = {model.state_dict()[layer].cpu().detach().numpy().shape}\")\n",
    "    tot_params += model.state_dict()[layer].cpu().numpy().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf7d233a-a1a9-4b03-affa-740d30b7d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters = 2043917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of trainable parameters = {tot_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed4372-0f95-4b8b-b4a3-e15a281205f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d7b9a-32a1-4f9f-8c10-fdf93e5cfe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5933a31-df69-4ebc-9f5c-5426ee3780a9",
   "metadata": {},
   "source": [
    "### Multi-GPU Training in PyTorch\n",
    "\n",
    "- [Multi-GPU Examples](https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html)\n",
    "\n",
    "- [Data Parallelism](https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3bf00c-4132-4369-8b8a-2bbbe604ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all available GPUs-\n",
    "# model = nn.DataParallel(model)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e79c48-6c23-4bf8-a8ea-7913324420e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90cc3550-f058-43b6-bb90-cb6c75667867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function-\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define SGD optimizer-\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 10e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04d141-8f59-41e5-840f-24a36e8d8aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c03a1af-5e31-41df-b5f1-acfdd2c32543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 dict to contain metrics-\n",
    "train_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c5537-2e4c-4f02-b835-cb75be6d91ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c697d5b-22db-4788-9153-38c3af6eb496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea864ea8-a148-409b-ac38-2eeb18519a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    '''\n",
    "    Function to train model for specified number of epochs.\n",
    "    '''\n",
    "    \n",
    "    # Set model to train-\n",
    "    model.train()\n",
    "    \n",
    "    best_loss = 100\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        \n",
    "        for batch, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Empty accumulated gradients-\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Make LSTM predictions-\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            \n",
    "            # Compute cross-entropy loss-\n",
    "            loss = loss_criterion(y_pred.transpose(1, 2), y)\n",
    "            \n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            \n",
    "            # Perform backprop-\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update parameters-\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Save best weights achieved until now-\n",
    "        if (loss.item() < best_loss):\n",
    "            # update 'best_loss' variable to lowest loss encountered so far-\n",
    "            best_loss = loss.item()\n",
    "\n",
    "            print(f\"Saving model with lowest loss = {loss.item():.5f}\\n\")\n",
    "        \n",
    "            # Save trained model with 'best' loss-\n",
    "            torch.save(model.state_dict(), \"Language_Model_best_model.pth\")\n",
    "        \n",
    "        print(f\"epoch: {epoch}, loss = {loss.item():.5f}\\n\")\n",
    "        train_history[epoch] = loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e4d9e-ccfe-4128-b373-5c406a6931db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596ff9f7-7c19-4c6f-9f35-7331b80f04c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model with lowest loss = 6.62055\n",
      "\n",
      "epoch: 1, loss = 6.62055\n",
      "\n",
      "Saving model with lowest loss = 5.74857\n",
      "\n",
      "epoch: 2, loss = 5.74857\n",
      "\n",
      "Saving model with lowest loss = 5.31697\n",
      "\n",
      "epoch: 3, loss = 5.31697\n",
      "\n",
      "Saving model with lowest loss = 4.94646\n",
      "\n",
      "epoch: 4, loss = 4.94646\n",
      "\n",
      "Saving model with lowest loss = 4.49212\n",
      "\n",
      "epoch: 5, loss = 4.49212\n",
      "\n",
      "Saving model with lowest loss = 3.84875\n",
      "\n",
      "epoch: 6, loss = 3.84875\n",
      "\n",
      "Saving model with lowest loss = 3.53967\n",
      "\n",
      "epoch: 7, loss = 3.53967\n",
      "\n",
      "Saving model with lowest loss = 3.22572\n",
      "\n",
      "epoch: 8, loss = 3.22572\n",
      "\n",
      "Saving model with lowest loss = 2.61579\n",
      "\n",
      "epoch: 9, loss = 2.61579\n",
      "\n",
      "Saving model with lowest loss = 2.44946\n",
      "\n",
      "epoch: 10, loss = 2.44946\n",
      "\n",
      "Saving model with lowest loss = 2.09015\n",
      "\n",
      "epoch: 11, loss = 2.09015\n",
      "\n",
      "Saving model with lowest loss = 1.90077\n",
      "\n",
      "epoch: 12, loss = 1.90077\n",
      "\n",
      "Saving model with lowest loss = 1.65849\n",
      "\n",
      "epoch: 13, loss = 1.65849\n",
      "\n",
      "Saving model with lowest loss = 1.46817\n",
      "\n",
      "epoch: 14, loss = 1.46817\n",
      "\n",
      "Saving model with lowest loss = 1.29430\n",
      "\n",
      "epoch: 15, loss = 1.29430\n",
      "\n",
      "Saving model with lowest loss = 1.28538\n",
      "\n",
      "epoch: 16, loss = 1.28538\n",
      "\n",
      "Saving model with lowest loss = 1.04728\n",
      "\n",
      "epoch: 17, loss = 1.04728\n",
      "\n",
      "Saving model with lowest loss = 0.87531\n",
      "\n",
      "epoch: 18, loss = 0.87531\n",
      "\n",
      "Saving model with lowest loss = 0.80244\n",
      "\n",
      "epoch: 19, loss = 0.80244\n",
      "\n",
      "epoch: 20, loss = 0.88635\n",
      "\n",
      "Saving model with lowest loss = 0.74218\n",
      "\n",
      "epoch: 21, loss = 0.74218\n",
      "\n",
      "Saving model with lowest loss = 0.59700\n",
      "\n",
      "epoch: 22, loss = 0.59700\n",
      "\n",
      "Saving model with lowest loss = 0.51195\n",
      "\n",
      "epoch: 23, loss = 0.51195\n",
      "\n",
      "Saving model with lowest loss = 0.49207\n",
      "\n",
      "epoch: 24, loss = 0.49207\n",
      "\n",
      "Saving model with lowest loss = 0.43231\n",
      "\n",
      "epoch: 25, loss = 0.43231\n",
      "\n",
      "Saving model with lowest loss = 0.37387\n",
      "\n",
      "epoch: 26, loss = 0.37387\n",
      "\n",
      "Saving model with lowest loss = 0.34203\n",
      "\n",
      "epoch: 27, loss = 0.34203\n",
      "\n",
      "Saving model with lowest loss = 0.29340\n",
      "\n",
      "epoch: 28, loss = 0.29340\n",
      "\n",
      "Saving model with lowest loss = 0.29049\n",
      "\n",
      "epoch: 29, loss = 0.29049\n",
      "\n",
      "Saving model with lowest loss = 0.23855\n",
      "\n",
      "epoch: 30, loss = 0.23855\n",
      "\n",
      "Saving model with lowest loss = 0.22609\n",
      "\n",
      "epoch: 31, loss = 0.22609\n",
      "\n",
      "Saving model with lowest loss = 0.16785\n",
      "\n",
      "epoch: 32, loss = 0.16785\n",
      "\n",
      "epoch: 33, loss = 0.20821\n",
      "\n",
      "epoch: 34, loss = 0.16933\n",
      "\n",
      "epoch: 35, loss = 0.17032\n",
      "\n",
      "Saving model with lowest loss = 0.14896\n",
      "\n",
      "epoch: 36, loss = 0.14896\n",
      "\n",
      "epoch: 37, loss = 0.15324\n",
      "\n",
      "epoch: 38, loss = 0.17118\n",
      "\n",
      "epoch: 39, loss = 0.16334\n",
      "\n",
      "Saving model with lowest loss = 0.13815\n",
      "\n",
      "epoch: 40, loss = 0.13815\n",
      "\n",
      "epoch: 41, loss = 0.14187\n",
      "\n",
      "Saving model with lowest loss = 0.11643\n",
      "\n",
      "epoch: 42, loss = 0.11643\n",
      "\n",
      "Saving model with lowest loss = 0.09777\n",
      "\n",
      "epoch: 43, loss = 0.09777\n",
      "\n",
      "Saving model with lowest loss = 0.09664\n",
      "\n",
      "epoch: 44, loss = 0.09664\n",
      "\n",
      "epoch: 45, loss = 0.14863\n",
      "\n",
      "epoch: 46, loss = 0.13771\n",
      "\n",
      "Saving model with lowest loss = 0.08913\n",
      "\n",
      "epoch: 47, loss = 0.08913\n",
      "\n",
      "epoch: 48, loss = 0.09725\n",
      "\n",
      "Saving model with lowest loss = 0.08682\n",
      "\n",
      "epoch: 49, loss = 0.08682\n",
      "\n",
      "epoch: 50, loss = 0.10287\n",
      "\n",
      "epoch: 51, loss = 0.10118\n",
      "\n",
      "Saving model with lowest loss = 0.07729\n",
      "\n",
      "epoch: 52, loss = 0.07729\n",
      "\n",
      "Saving model with lowest loss = 0.06466\n",
      "\n",
      "epoch: 53, loss = 0.06466\n",
      "\n",
      "epoch: 54, loss = 0.09131\n",
      "\n",
      "epoch: 55, loss = 0.08915\n",
      "\n",
      "epoch: 56, loss = 0.09446\n",
      "\n",
      "epoch: 57, loss = 0.07942\n",
      "\n",
      "epoch: 58, loss = 0.08270\n",
      "\n",
      "epoch: 59, loss = 0.09459\n",
      "\n",
      "epoch: 60, loss = 0.10078\n",
      "\n",
      "epoch: 61, loss = 0.08415\n",
      "\n",
      "epoch: 62, loss = 0.06550\n",
      "\n",
      "Saving model with lowest loss = 0.04956\n",
      "\n",
      "epoch: 63, loss = 0.04956\n",
      "\n",
      "Saving model with lowest loss = 0.03999\n",
      "\n",
      "epoch: 64, loss = 0.03999\n",
      "\n",
      "epoch: 65, loss = 0.05211\n",
      "\n",
      "epoch: 66, loss = 0.04669\n",
      "\n",
      "epoch: 67, loss = 0.04991\n",
      "\n",
      "Saving model with lowest loss = 0.03778\n",
      "\n",
      "epoch: 68, loss = 0.03778\n",
      "\n",
      "epoch: 69, loss = 0.03958\n",
      "\n",
      "epoch: 70, loss = 0.05787\n",
      "\n",
      "Saving model with lowest loss = 0.03731\n",
      "\n",
      "epoch: 71, loss = 0.03731\n",
      "\n",
      "epoch: 72, loss = 0.04272\n",
      "\n",
      "epoch: 73, loss = 0.04170\n",
      "\n",
      "epoch: 74, loss = 0.04765\n",
      "\n",
      "Saving model with lowest loss = 0.02801\n",
      "\n",
      "epoch: 75, loss = 0.02801\n",
      "\n",
      "epoch: 76, loss = 0.04569\n",
      "\n",
      "epoch: 77, loss = 0.04442\n",
      "\n",
      "epoch: 78, loss = 0.07045\n",
      "\n",
      "epoch: 79, loss = 0.06154\n",
      "\n",
      "epoch: 80, loss = 0.03901\n",
      "\n",
      "epoch: 81, loss = 0.09005\n",
      "\n",
      "epoch: 82, loss = 0.11474\n",
      "\n",
      "epoch: 83, loss = 0.12374\n",
      "\n",
      "epoch: 84, loss = 0.15819\n",
      "\n",
      "epoch: 85, loss = 0.21990\n",
      "\n",
      "epoch: 86, loss = 0.26084\n",
      "\n",
      "epoch: 87, loss = 0.33448\n",
      "\n",
      "epoch: 88, loss = 0.12522\n",
      "\n",
      "epoch: 89, loss = 0.07755\n",
      "\n",
      "epoch: 90, loss = 0.08523\n",
      "\n",
      "epoch: 91, loss = 0.05481\n",
      "\n",
      "epoch: 92, loss = 0.05505\n",
      "\n",
      "epoch: 93, loss = 0.03027\n",
      "\n",
      "epoch: 94, loss = 0.02822\n",
      "\n",
      "Saving model with lowest loss = 0.01556\n",
      "\n",
      "epoch: 95, loss = 0.01556\n",
      "\n",
      "epoch: 96, loss = 0.02555\n",
      "\n",
      "epoch: 97, loss = 0.02108\n",
      "\n",
      "Saving model with lowest loss = 0.01116\n",
      "\n",
      "epoch: 98, loss = 0.01116\n",
      "\n",
      "epoch: 99, loss = 0.01690\n",
      "\n",
      "epoch: 100, loss = 0.01420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model-\n",
    "train(model = model, train_loader = dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741b40e-c238-42a1-9f9f-35f3ae93179c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2056c9-356f-494e-9355-e4939d5c34a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d9ebf5d-752c-4395-b189-9866bc4c9a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training-\n",
    "plt.figure(figsize = (8, 7))\n",
    "plt.plot([train_history[epoch] for epoch in train_history.keys()])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Language Model Visualization: training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46181909-db29-4c7e-aac5-57418df6d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfc648-4182-4054-8727-871efdf3e6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b704fae-d3b4-45df-ba6b-6852ab656e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, text, next_words = 100):\n",
    "    '''\n",
    "    Synthesize new sequences using 'text' as input.\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        x = x.to(device)\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim = 0).cpu().detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p = p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529143e2-62ca-4ad4-a775-5650ee69c191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23c02861-d24f-46ae-9cc0-a7e0b09e757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new words using trained model-\n",
    "synthesized_words = predict(model = model, dataset = dataset,\n",
    "        text = 'Knock knock. Whos there?', next_words = 5\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ee03ad5-fc21-42ab-9fbf-3d926d492d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Knock', 'knock.', 'Whos', 'there?', 'cables?', 'You', 'better', 'not', 'try']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18549c-30ba-40a8-ac19-b8c9f30f29cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab0d93-2204-4567-a66c-e5a7438d777c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b35821-9cca-4150-ab6f-e6e6e819ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load trained model-\n",
    "trained_model = LSTM_Model(\n",
    "    dataset = dataset, lstm_size = 128,\n",
    "    embedding_dim = 128, num_layers = 2\n",
    ").to(device)\n",
    "\n",
    "trained_model.load_state_dict(torch.load(\"Language_Model_best_model.pth\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fea3b-8742-4d7a-8fc2-eb2b1633fa30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1620b4e-e57b-4847-8a56-ab59d97c4f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c57991c-62d9-44a4-a56f-5e5e6dc4adc1",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "\n",
    "\n",
    "- Clean up the data by removing non-letter characters.\n",
    "\n",
    "- Increase the model capacity by adding more Linear or LSTM layers.\n",
    "\n",
    "- Split the dataset into train, test, and validation sets.\n",
    "\n",
    "- Add checkpoints so you don't have to train the model every time you want to run prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986da650-d284-4149-a93e-c13ad9891f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195169aa-28e8-4cad-beb5-d873297e191a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
