{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4b8084-799a-461f-98d6-db7dcbdc819f",
   "metadata": {},
   "source": [
    "# Difference between ```return_sequence``` and ```return_state``` for LSTMs in TF2 Keras\n",
    "\n",
    "As part of TF2 LSTM implementation, the Keras API provides access to both _return sequences_ and _return state_. The use and difference between these data can be confusing when designing sophisticated recurrent neural network models, such as the encoder-decoder model.\n",
    "\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "- __That return sequences return the hidden state output for each input time step__.\n",
    "\n",
    "- __That return state returns the hidden state output and cell state for the last input time step__.\n",
    "\n",
    "- __That return sequences and return state can be used at the same time__.\n",
    "\n",
    "\n",
    "#### Long Short-Term Memory RNN\n",
    "\n",
    "- Creating a layer of LSTM memory units allows you to specify the number of memory units within the layer.\n",
    "\n",
    "- Each unit or cell within the layer has an _internal cell_ state, often abbreviated as “c“, and _outputs a hidden state_, often abbreviated as “h“.\n",
    "\n",
    "The Keras API allows you to access these data, which can be useful or even required when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model.\n",
    "\n",
    "For the rest of this tutorial, we will look at the API for access these data.\n",
    "\n",
    "\n",
    "[Tutorial](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa2f6b-6a67-4ae5-bb13-176c35d27359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5d3405-89b8-45fe-b939-182b60067cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, LeakyReLU, Reshape\n",
    "from tensorflow.keras.layers import LSTM, GRU, Input, Flatten, Dense, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed, Dropout\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly\n",
    "# import plotly.express as px\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe937e-b3a0-4928-ac62-a2f89427c3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e055e-2760-4731-bcbe-b3101543bd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581c45e0-e2b5-43f0-a9e9-7a93b1988277",
   "metadata": {},
   "source": [
    "### Return Sequences\n",
    "\n",
    "__Each LSTM cell will output one hidden state h for each input__.\n",
    "\n",
    "We can demonstrate this in Keras with _a very small model with a single LSTM layer that itself contains a single LSTM cell_.\n",
    "\n",
    "Here, we will have _one input sample with 3 time steps and one feature observed at each time step_:\n",
    "```\n",
    "t1 = 0.1\n",
    "t2 = 0.2\n",
    "t3 = 0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c30a76f4-c099-4037-a328-435814264599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a LSTM layer having one LSTM cell-\n",
    "lstm_layer = LSTM(units = 1, input_shape = (3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee228d-8c29-469f-ab4c-2a7c9a72bc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f3067b1-9665-4d04-9a00-144496570b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with one feature having 3 time steps-\n",
    "X = np.array([0.1, 0.2, 0.3]).reshape((1, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16da06d9-7303-47f4-a9b8-4f2e0076ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853083b-9d35-46e5-94bb-37db6973d8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6ee6a77-0984-4b4a-861c-b224bd2e509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output for a single hidden state for the input sequence with 3 time steps-\n",
    "output = lstm_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5814fbc9-92b5-4eee-822a-1232dd21e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for a single hidden state for an input with one feature and 3 time steps = 0.0210\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output for a single hidden state for an input with one feature and 3 time steps = {output.numpy()[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01aa59-a9aa-4cec-be98-b6f9893f91d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f3c16b-334a-4503-af02-cb91b4d27f4a",
   "metadata": {},
   "source": [
    "#### Access the _hidden state output_ for each input time step\n",
    "\n",
    "It is possible to access the hidden state output for each input time step. This can be done by setting the ```return_sequences``` attribute to True when defining the LSTM layer, as follows-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc4654b3-293e-4ff1-ac64-8b414aafe2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM layer to access hidden state output for each input time step-\n",
    "lstm_layer = LSTM(\n",
    "    units = 1, return_sequences = True,\n",
    "    input_shape = (3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd334117-f5f0-4680-83d4-539c4c2afd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output for input sequence with 3 time steps-\n",
    "output = lstm_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "481c4b78-c8f4-427d-a320-1d3f414b71a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for each time step:\n",
      "[[[0.01174813]\n",
      "  [0.03592343]\n",
      "  [0.07357237]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output for each time step:\\n{output.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5a1d3-3581-4a70-ad9d-2f9982989b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc76ab22-14b7-478c-b21b-3744a5063e15",
   "metadata": {},
   "source": [
    "Note: You must set ```return_sequences = True``` when stacking LSTM layers so that the second LSTM layer has a three-dimensional sequence input. For more details, refer to [Stacked Long Short-Term Memory Networks](https://machinelearningmastery.com/stacked-long-short-term-memory-networks/)\n",
    "\n",
    "You may also need to access the sequence of hidden state outputs when predicting a sequence of outputs with a Dense output layer wrapped in a ```TimeDistributed``` layer. Refer to [How to Use the TimeDistributed Layer for Long Short-Term Memory Networks in Python](https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c2ac8-4b0c-44a5-8032-40b9056e4ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a6b58-261a-424c-bdfa-8361c30681cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b44d7e-d834-4c6e-8224-e99eee76b989",
   "metadata": {},
   "source": [
    "### Return States\n",
    "\n",
    "- __The output of an LSTM cell or layer of cells is called the hidden state__. This is confusing, because __each LSTM cell retains an internal state that is not output, called the cell state, or c__.\n",
    "\n",
    "- Generally, we do not need to access the cell state unless we are developing sophisticated models where subsequent layers may need to have their cell state initialized with the final cell state of another layer, such as in an encoder-decoder model.\n",
    "\n",
    "Keras provides the ```return_state``` argument in the LSTM layer that will provide access to the hidden state output ```(state_h)``` and the cell state ```(state_c)```. For example-\n",
    "\n",
    "```\n",
    "lstm1, state_h, state_c = LSTM(units = 1, return_state = True)\n",
    "```\n",
    "\n",
    "This may look confusing because both ```lstm1``` and ```state_h``` refer to the same hidden state output. The reason for these two tensors being separate will become clear in the next section.\n",
    "\n",
    "We can demonstrate access to the hidden and cell states of the cells in the LSTM layer as follows-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5465dac9-c312-4f7e-91a0-3a0929af3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model-\n",
    "inputs1 = Input(shape = (3, 1))\n",
    "lstm1, state_h, state_c = LSTM(units = 1, return_state = True)(inputs1)\n",
    "model = Model(inputs = inputs1, outputs = [lstm1, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b2f97c3-891b-4a14-9bc7-3436b73d9e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.09086772]], dtype=float32),\n",
       " array([[-0.09086772]], dtype=float32),\n",
       " array([[-0.18937905]], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get LSTM's predictions-\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce8cb7-e117-4f9b-8679-8731f2a33101",
   "metadata": {},
   "source": [
    "Running the example returns 3 arrays:\n",
    "\n",
    "- The LSTM hidden state output for the last time step.\n",
    "- The LSTM hidden state output for the last time step (again).\n",
    "- The LSTM cell state for the last time step.\n",
    "\n",
    "__The hidden state and the cell state could in turn be used to initialize the states of another LSTM layer with the same number of cells_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00108cb6-1c88-433c-810d-991c5cdc4096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4a5cd7b-f792-43c2-9479-a3319e6405bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check (without using Model)-\n",
    "lstm_layer = LSTM(\n",
    "    units = 1, return_state = True,\n",
    "    input_shape = (3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f9f8d28-b7b5-4ab7-a123-50bd7bade54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.07009666]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.07009666]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.14744249]], dtype=float32)>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4554c5f-0101-4d0c-93a8-b68ac8802f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b348116-085c-403e-9c41-2e752c1fa2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef14ce2-e505-4d41-9fa8-d20c6cb3b016",
   "metadata": {},
   "source": [
    "### Return States and Sequences\n",
    "\n",
    "We can access both the sequence of hidden state and the cell states at the same time. This can be done by configuring the LSTM layer to return both sequences and return states. An examples is:\n",
    "\n",
    "```\n",
    "lstm1, state_h, state_c = LSTM(1, return_sequences = True, return_state = True)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adc109a0-c66f-4554-9b4c-8a11dfade680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model-\n",
    "inputs1 = Input(shape = (3, 1))\n",
    "lstm1, state_h, state_c = LSTM(\n",
    "    units = 1, return_sequences = True,\n",
    "    return_state = True)(inputs1)\n",
    "\n",
    "model = Model(inputs = inputs1, outputs = [lstm1, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "825a0347-7ca3-4416-a183-394e7abd004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.00882794],\n",
       "         [-0.02347509],\n",
       "         [-0.04204081]]], dtype=float32),\n",
       " array([[-0.04204081]], dtype=float32),\n",
       " array([[-0.07500947]], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions-\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b70309-c00d-4591-8736-0f35384c9ae4",
   "metadata": {},
   "source": [
    "Running the example, we can now see why the LSTM output tensor and hidden state output tensor are declared separably.\n",
    "\n",
    "- __The layer returns the hidden state for each input time step, then separately, the hidden state output for the last time step and the cell state for the last input time step__.\n",
    "\n",
    "- This can be confirmed by seeing that the last value in the returned sequences (first array) matches the value in the hidden state (second array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4b5b6-eeb7-42d2-8655-3ac30d183cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5d44cab-91c1-46e5-aba1-516d94177554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check (without using Model)-\n",
    "lstm_layer = LSTM(\n",
    "    units = 1, return_state = True,\n",
    "    return_sequences = True, input_shape = (3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1000521b-8c9e-4bbf-bfbc-50efb6b9c80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 3, 1), dtype=float32, numpy=\n",
       " array([[[0.00771256],\n",
       "         [0.0218019 ],\n",
       "         [0.04130548]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.04130548]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.07166928]], dtype=float32)>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c3c2b-7867-4e0a-8912-110aedf0571f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e5766-fecd-4c62-8dfb-366b63b28a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0060fad-8a1f-456c-ac92-966f5fe64a3e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We saw that:\n",
    "\n",
    "- return sequences return the hidden state output for each input time step.\n",
    "- return state returns the hidden state output and cell state for the last input time step.\n",
    "- return sequences and return state can be used at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e73acf-4358-4879-9494-0413af14ff80",
   "metadata": {},
   "source": [
    "#### Additional URLs\n",
    "\n",
    "- [Reference](https://www.kaggle.com/code/kmkarakaya/lstm-output-types-return-sequences-state/notebook)\n",
    "\n",
    "- [Reference2](https://sanjivgautamofficial.medium.com/lstm-in-keras-56a59264c0b2)\n",
    "\n",
    "- [Reference3](https://www.dlology.com/blog/how-to-use-return_state-or-return_sequences-in-keras/)\n",
    "\n",
    "- [StackOverflow](https://stackoverflow.com/questions/42755820/how-to-use-return-sequences-option-and-timedistributed-layer-in-keras)\n",
    "\n",
    "- [Reference4](https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/LSTM_Understanding_Output_Types.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a7f43-531d-42fe-a93d-726a41c96fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354056e0-ea69-4d73-94f2-714d42b45891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
