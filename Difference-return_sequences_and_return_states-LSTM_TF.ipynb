{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d60fc6-1e53-48f6-87fa-561680ae3f88",
   "metadata": {},
   "source": [
    "# Difference Between Return Sequences and Return States for LSTMs in TensorFlow Keras\n",
    "\n",
    "The Keras deep learning library provides an implementation of the _Long Short-Term Memory_, or LSTM, recurrent neural network.\n",
    "\n",
    "As part of this implementation, the Keras API provides access to both _return sequences_ and _return state_. The use and difference between these data can be confusing when designing sophisticated recurrent neural network models, such as the encoder-decoder model.\n",
    "\n",
    "[Reference](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8386719e-f0b0-49f5-8fd0-c4ff2a9c4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Flatten, LSTM, Bidirectional, GRU, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317455e-1848-4d25-9cc5-85233e2b5465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3bb8a-93d4-4f17-9f8e-1aa2014b5b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15284ee-7c6c-450d-8868-6fdbedf1ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ea3ae1-7f70-49ba-8f0f-49f79c179000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availibility-\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(f\"GPU: {gpu_devices}\")\n",
    "\n",
    "if gpu_devices:\n",
    "    print(f\"GPU: {gpu_devices}\")\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    print(f\"GPU details: {details.get('device_name', 'Unknown GPU')}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d6eae-3088-46df-af52-e3e7b23bc228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6b274-5811-4c84-b1b8-08d3080cb621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7922a3-eb1d-4426-b38d-f2c2cb8211b4",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory\n",
    "\n",
    "- The Long Short-Term Memory, or __LSTM__, is a recurrent neural network that is __comprised of internal gates__.\n",
    "\n",
    "- Unlike other recurrent neural networks, the network’s internal gates allow the model to be trained successfully using backpropagation through time, or BPTT, and avoid the vanishing gradients problem.\n",
    "\n",
    "- In the Keras deep learning library, LSTM layers can be created using the ```LSTM()``` class.\n",
    "\n",
    "- __Creating a layer of LSTM memory units allows you to specify the number of memory units within the layer__.\n",
    "\n",
    "- __Each unit or cell within the layer has an internal cell state, often abbreviated as “c“, and outputs a hidden state, often abbreviated as “h“__.\n",
    "\n",
    "The Keras API allows you to access these data, which can be useful or even required when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade4167-d3c9-4ffb-998b-d238557db3d6",
   "metadata": {},
   "source": [
    "#### Return Sequences\n",
    "\n",
    "__Each LSTM cell will output one hidden state _h_ for each input__.\n",
    "\n",
    "```h = LSTM(X)```\n",
    "\n",
    "We can demonstrate this in Keras with a very small model with a single LSTM layer that itself contains a single LSTM cell.\n",
    "\n",
    "In this example, we will have one input sample with 3 time steps and one feature observed at each time step:\n",
    "\n",
    "```\n",
    "t1 = 0.1\n",
    "t2 = 0.2\n",
    "t3 = 0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a114351-9ec5-41f5-b07e-f4a241a42c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model-\n",
    "inputs1 = Input(shape = (3, 1))\n",
    "lstm1 = LSTM(\n",
    "    units = 1, activation = tf.keras.activations.tanh\n",
    ")(inputs1)\n",
    "model = Model(inputs = inputs1, outputs = lstm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566bfb1d-cfca-455f-86c8-31fd9126c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary-\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca562e-5fc3-4419-a402-82d056fd84e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06f776a-eb8c-4a4b-b312-72bf1c2b5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape: (1, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define input data-\n",
    "data = np.array([0.1, 0.2, 0.3]).reshape((1, 3, 1))\n",
    "print(f\"Input sequence shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22646c5c-7f90-40e7-9055-ce2c67329e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09937763]]\n"
     ]
    }
   ],
   "source": [
    "# Predict for this data-\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f784d2-0c56-4927-8a9c-37fffcfa023a",
   "metadata": {},
   "source": [
    "Running this code example __outputs a single hidden state for the input sequence with 3 time steps__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6652576-25b3-438e-85ac-10c95222da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9547a95-f9a0-4cba-8c90-838ff36b2641",
   "metadata": {},
   "source": [
    "- It is __possible to access the hidden state output for each input time step__.\n",
    "\n",
    "- This can be done by setting the ```return_sequences``` attribute to ```True``` when defining the LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b1ca8a-a6f6-4a63-a89b-980ed82940b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model to access hidden state output for each time step-\n",
    "lstm1 = LSTM(\n",
    "    units = 1, activation = tf.keras.activations.tanh,\n",
    "    return_sequences = True\n",
    ")(inputs1)\n",
    "model = Model(inputs = inputs1, outputs = lstm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "341db32a-feba-4247-b304-63afff4e0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 3, 1)              12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary-\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1106f5a3-9898-4b34-88a5-ce2027e3cdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.01469561],\n",
       "        [0.04029939],\n",
       "        [0.07396863]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for the input data above-\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba690249-300d-468e-8504-9bd4ce5509ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56adbe4e-5b4f-4aff-9a69-3fc8abc95fa7",
   "metadata": {},
   "source": [
    "This code example __returns a sequence of 3 values, one hidden state output for each input time step for the single LSTM cell in the layer__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1769094-83fc-44d5-a4de-0b6b7f50987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb01278-1f02-4651-8d07-a48096992a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model to access hidden state output for each time step-\n",
    "lstm1 = LSTM(\n",
    "    units = 12, activation = tf.keras.activations.tanh,\n",
    "    return_sequences = True\n",
    ")(inputs1)\n",
    "model = Model(inputs = inputs1, outputs = lstm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a3e628-818c-4235-b697-8035f68d8fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for the input data above-\n",
    "model.predict(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7834b1-209a-4a57-a3ab-1c6bf6d05360",
   "metadata": {},
   "source": [
    "This code example __returns a sequence of 3 values, one hidden state output for each input time step for all _12_ LSTM cell in the layer__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1862110-daa0-40c8-933d-b579a39b47af",
   "metadata": {},
   "source": [
    "- You must set ```return_sequences=True``` when stacking LSTM layers so that the second LSTM layer has a three-dimensional sequence input. Refer to [   Stacked Long Short-Term Memory Networks](https://machinelearningmastery.com/stacked-long-short-term-memory-networks/) for more details.\n",
    "\n",
    "- You may also need to access the sequence of hidden state outputs when predicting a sequence of outputs with a Dense output layer wrapped in a ```TimeDistributed``` layer. Refer to [How to Use the TimeDistributed Layer for Long Short-Term Memory Networks in Python](https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882700c-b0b7-49ec-b205-d33249984c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603e2d5-68c3-42e1-adf2-acbadb0f8749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d0f8a23-7f98-4dcd-982f-fc69530dc394",
   "metadata": {},
   "source": [
    "### Return States\n",
    "\n",
    "- __The output of an LSTM cell or layer of cells is called the hidden state__.\n",
    "\n",
    "- This is confusing, because __each LSTM cell retains an internal state that is not output, called the _cell state_, or _c___.\n",
    "\n",
    "- __Generally, we do not need to access the cell state (or, internal state) unless we are developing sophisticated models where subsequent layers may need to have their cell state initialized with the final cell state of another layer__, such as in an encoder-decoder model.\n",
    "\n",
    "- Keras provides the ```return_state``` argument to the LSTM layer that will provide access to the hidden state output (_state_h_) and the cell state (_state_c_). As an example-\n",
    "\n",
    "```\n",
    "lstm1, state_h, state_c = LSTM(units = 1, return_state = True)\n",
    "```\n",
    "\n",
    "- __This may look confusing because both ```lstm1``` and ```state_h``` refer to the same hidden state output__. The reason for these two tensors being separate will become clear in the next section.\n",
    "\n",
    "- We can demonstrate access to the hidden and cell states of the cells in the LSTM layer with a worked example listed below-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2528b50-5c3d-4949-bb90-4657fd117efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model-\n",
    "lstm1, state_h, state_c = LSTM(\n",
    "    units = 1, activation = tf.keras.activations.tanh,\n",
    "    return_state = True)(inputs1)\n",
    "\n",
    "model = Model(inputs = inputs1, outputs = [lstm1, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88ccd61e-e070-465b-9433-2df9077507e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               [(None, 1),               12        \n",
      "                              (None, 1),                         \n",
      "                              (None, 1)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary-\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f71c56-f6b9-46ba-a64e-57e81828b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b17613ee-5113-4dde-bf3f-adc6189be0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.06094353]], dtype=float32),\n",
       " array([[0.06094353]], dtype=float32),\n",
       " array([[0.11918673]], dtype=float32)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for the input data above-\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e5002-5f7f-4a4d-b48a-d4de0db14827",
   "metadata": {},
   "source": [
    "- This returns 3 arrays:\n",
    "    1. The LSTM hidden state output for the last time step.\n",
    "    1. The LSTM hidden state output for the last time step (again).\n",
    "    1. The LSTM cell state for the last time step.\n",
    "    \n",
    "- The hidden state and the cell state could in turn be used to initialize the states of another LSTM layer with the same number of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bf57a-7dec-4153-a47f-14bda6d7aeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd90fc-a7c1-4010-bbb4-839dfa29abfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "125b5f98-9d3c-4833-9b34-ab091d5b6730",
   "metadata": {},
   "source": [
    "# Return States and Sequences\n",
    "\n",
    "- We can access both the sequence of hidden states and the cell states at the same time.\n",
    "\n",
    "- This can be done by configuring the LSTM layer to both return sequences and return states-\n",
    "```\n",
    "lstm1, state_h, state_c = LSTM(\n",
    "    units = 1, return_sequences = True,\n",
    "    return_state = True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cfff3a5-3388-484f-b94c-8530164082f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model-\n",
    "lstm1, state_h, state_c = LSTM(\n",
    "    units = 1, activation = tf.keras.activations.tanh,\n",
    "    return_sequences = True, return_state = True)(inputs1)\n",
    "\n",
    "model = Model(inputs = inputs1, outputs = [lstm1, state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e355233-31f7-46d9-877c-939466f5d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               [(None, 3, 1),            12        \n",
      "                              (None, 1),                         \n",
      "                              (None, 1)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48b561-18e4-4741-900f-9aeac069be96",
   "metadata": {},
   "source": [
    "- With this code example, we can see now why the LSTM output tensor and hidden state output tensor are declared separably.\n",
    "\n",
    "- The layer returns:\n",
    "    - the hidden state for each input time step, (and then separately),\n",
    "    - the hidden state output for the last time step (and)\n",
    "    - the cell state for the last input time step.\n",
    "\n",
    "- This can be confirmed by seeing that the last value in the returned sequences (first array) matches the value in the hidden state (second array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e665b844-dd80-4e59-8e99-462462409c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using LSTM-\n",
    "lstm_output = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "679c4d44-72fb-48cf-8823-833d17ca7943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lstm_output), len(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe59abe-bd8f-4fcd-85a4-71efd0191ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state for each time step shape: (1, 3, 1), hidden state output for last time step shape: (1, 1) & cell state output for last time step shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hidden state for each time step shape: {lstm_output[0].shape},\"\n",
    "      f\" hidden state output for last time step shape: {lstm_output[1].shape}\"\n",
    "      f\" & cell state output for last time step shape: {lstm_output[2].shape}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25fcfae6-6641-4a7f-a12d-ad4b94ee58f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10932464"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output[0][0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47259444-be7c-4f34-adc1-fa1a9ca1c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state output for last time-step = [0.10932464] & cell state output for last time-step = [0.19064409]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hidden state output for last time-step = {lstm_output[1][0]} &\"\n",
    "      f\" cell state output for last time-step = {lstm_output[2][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433478a2-2865-466c-b39c-27b957ace9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6443aa1-fee8-4847-879d-51989c91de4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
