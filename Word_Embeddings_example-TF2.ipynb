{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d07d0bb-0cb6-47b7-ba85-62daff87b9e0",
   "metadata": {},
   "source": [
    "# Using _Word Embedding_ Layer in TensorFlow-2.8\n",
    "\n",
    "- A word embedding is a class of approaches for representing words and documents using a dense vector representation.\n",
    "\n",
    "- It is an improvement over the more traditional bag-of-word model encoding schemes where large sparse vectors were used to represent each word or to score each word within a vector to represent an entire vocabulary. These representations were sparse because the vocabularies were vast and a given word or document would be represented by a large vector comprised mostly of zero values.\n",
    "\n",
    "- Instead, __in an embedding, words are represented by dense vectors where a vector represents the projection of the word into a continuous vector space__.\n",
    "\n",
    "- __The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used__.\n",
    "\n",
    "- __The position of a word in the learned vector space is referred to as its embedding__.\n",
    "\n",
    "- Two popular examples of methods of learning word embeddings from text include:\n",
    "    - Word2Vec\n",
    "    - GloVe\n",
    "\n",
    "- In addition to these carefully designed _word representation_ methods, a word embedding can be learned as part of a deep learning model. This can be a slower approach, but tailors the model to a specific training dataset.\n",
    "\n",
    "\n",
    "[Reference](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535c12d-e177-47bc-b347-31b6334369e0",
   "metadata": {},
   "source": [
    "### Keras Embedding Layer\n",
    "\n",
    "- Keras offers an [Embedding](https://keras.io/api/layers/core_layers/embedding/#embedding) layer that can be used for neural networks on text data.\n",
    "\n",
    "- It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can also be performed using the [Tokenizer API](https://keras.io/api/preprocessing/text/#tokenizer) provided with Keras.\n",
    "\n",
    "- _The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset_.\n",
    "\n",
    "- It is a flexible layer that can be used in a variety of ways, such as:\n",
    "\n",
    "    - It can be used stand-alone to learn a word embedding that can be saved and used in another model later.\n",
    "    - It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "    - It can be used to load a pre-trained word embedding model, a type of transfer learning.\n",
    "\n",
    "- __The Embedding layer is defined as the first hidden layer of a network__. It must specify 3 arguments:\n",
    "    - __input_dim__: This is the _vocabulary size_ in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "    - __output_dim__: This is the embedded vector size of the vector space in which words will be embedded. __It defines the size of the output vectors from this layer for each word__. For example, it could be 32 or 100 or even larger. _Test different values for your problem_.\n",
    "    - __input_length__: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "As an example, we define the following ```Embedding``` layer with a vocabulary of 200 (e.g. integer encoded words from 0 to 199, inclusive), a vector space of 32 dimensions in which words will be embedded, and input documents that have 50 words each-\n",
    "\n",
    "```e = Embedding(input_dim = 200, output_dim = 32, input_length = 50)```\n",
    "\n",
    "- The Embedding layer has weights that are learned. If you save your model to file, this will include weights for the Embedding layer.\n",
    "\n",
    "- __The output of the ```Embedding``` layer is a 2D vector with one embedding for each word in the input sequence of words (input document)__.\n",
    "\n",
    "- __If you wish to connect a Dense layer directly to an Embedding layer, you must first flatten the 2D output matrix to a 1D vector using the ```Flatten``` layer__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee1a2a-1f91-4cd7-82fb-99d741a4f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Specify GPU to be used-\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df444a-9ad9-4719-89e4-71c3a99317e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090a95ab-e825-4730-8677-adce3d0ecd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732197c-7de7-4304-943a-dba5d9fe7e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a3418-1253-4359-92bf-c06a6cea3152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4032d5b-68ba-48d2-9cbb-87e7842ed29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641c45db-2324-4073-8393-8e2fa7ba4a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details: NVIDIA GeForce RTX 3080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availibility-\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "# print(f\"GPU: {gpu_devices}\")\n",
    "\n",
    "if gpu_devices:\n",
    "    print(f\"GPU: {gpu_devices}\")\n",
    "    details = tf.config.experimental.get_device_details(gpu_devices[0])\n",
    "    print(f\"GPU details: {details.get('device_name', 'Unknown GPU')}\")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cce91b-f2af-4036-870a-df7fc0a96160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57c00e-c5d3-465e-b5ab-4534b2f7bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbeabe1b-460d-43b3-b65b-f93e60060eae",
   "metadata": {},
   "source": [
    "#### Example of Learning an Embedding\n",
    "\n",
    "- We look at a tpy example of how we can learn a word embedding while training a neural network on a text classification problem.\n",
    "\n",
    "- We define a toy problem having 10 text documents, each with a comment about a piece of work a student submitted. Each text document is classified as positive _1_ or negative _0_. This is a simple sentiment analysis problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163de1ca-acbb-46bf-a2b3-dd104640d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example documents-\n",
    "docs = [\n",
    "    'Well done!',\n",
    "    'Good work',\n",
    "    'Great effort',\n",
    "    'nice work',\n",
    "    'Excellent!',\n",
    "    'Weak',\n",
    "    'Poor effort!',\n",
    "    'not good',\n",
    "    'poor work',\n",
    "    'Could have done better.'\n",
    "]\n",
    "\n",
    "# Define class labels-\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39cfd720-f68d-4a16-844a-fdb4e0383688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size-\n",
    "voc_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b393c-106f-4969-954b-70263e59aaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344702d-7db2-48e0-bde2-62cefc3b83e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d66f462-7da7-4c94-a5a0-e3c1256aefac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n",
      "Good work\n",
      "Great effort\n",
      "nice work\n",
      "Excellent!\n",
      "Weak\n",
      "Poor effort!\n",
      "not good\n",
      "poor work\n",
      "Could have done better.\n"
     ]
    }
   ],
   "source": [
    "# Example-\n",
    "for words in docs:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72ed4156-14ce-4156-b50d-1f24bb6b0c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could have done better.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9080b7a-004f-4e33-ab0b-eec12de13821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 1, 7, 22]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(input_text = words, n = voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3e653-1a02-45c6-973c-28136b0b122f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e971e5b0-df5c-49c0-8f34-1cc77545fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one-hot vectors-\n",
    "onehot_vec = [one_hot(input_text = words, n = voc_size) for words in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5654a61-863f-44de-abd5-b4ed52203c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onehot_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c207484-a853-446d-a861-b0e8dcbd9fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Well done!', [40, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print an example sentence and it's one-hot vector-\n",
    "docs[0], onehot_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a7912-ff81-402e-b386-f230ab64e525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e929be-1535-46ed-b20e-a057894687b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f557e35-0355-41ed-b1b7-6e6811d3c221",
   "metadata": {},
   "source": [
    "#### Pad documents/sequences\n",
    "\n",
    "The neural network expects all sentences to have the same size. To achieve this, _pad the input sentences_. For all of the given sentences, make it 4-word sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ecb538-49e2-4e4d-8a3a-1bc03e01e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(onehot_vec, maxlen = max_length, padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f8d8a0-e27b-4ce3-a9da-a40d32041489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 40  7]\n",
      " [ 0  0 33 45]\n",
      " [ 0  0 37 35]\n",
      " [ 0  0 47 45]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0 43 35]\n",
      " [ 0  0 37 33]\n",
      " [ 0  0 43 45]\n",
      " [13  1  7 22]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5b5382a-b903-4257-a4bc-a9c6c5813290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 4), 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape, len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "498472b0-e2df-4bf1-9dee-0b6eb0fad33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Well done!', [40, 7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0], onehot_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "588d5c53-fa5d-402b-904c-674958c7ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0, 40,  7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a03934-fdf7-4250-8ec9-995180361908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4004e-3c30-4c0f-b681-d6a96d7ee136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfb575a-1fb1-46f1-8308-88f97ec68525",
   "metadata": {},
   "source": [
    "### Embedding Layer\n",
    "\n",
    "creates the _feature representation_ for any word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf087224-5a98-498a-8223-6cc79a198a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify feature-vector length-\n",
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "742a37a2-77f7-44a5-8398-b5d02a711dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 50, embedding dimensionality = 10 & padded sentence input length = 4\n"
     ]
    }
   ],
   "source": [
    "# Sanity check-\n",
    "print(f\"Vocabulary size = {voc_size}, embedding dimensionality = \"\n",
    "      f\"{embedding_dim} & padded sentence input length = {max_length}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0232f6c-fd2e-42a3-8a83-513c2a3bfdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de2dc3c5-4c35-4969-a88d-308a296cd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Embedding layer-\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(\n",
    "        input_dim = voc_size, output_dim = embedding_dim,\n",
    "        embeddings_initializer = 'uniform',\n",
    "        embeddings_regularizer = None,\n",
    "        input_length = max_length\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units = 1, activation = tf.keras.activations.sigmoid\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7aeb700d-c13d-4d94-8517-5c9b43e25366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile defined model-\n",
    "model.compile(\n",
    "    # loss = tf.keras.losses.MeanSquaredError(),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137430b7-9432-41d6-8d90-684b2975304f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1739d0a6-6755-4a42-9a6d-fb71dfeb9d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 4, 10)             500       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get model summary-\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d7d9e-60d2-429e-b3d0-9b0fbb1aecd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a44925-e156-45c8-8370-21d6ae3f0241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e6469e-d34d-4f51-9a8e-cf362589cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted embedding shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted embedding shape: {model.predict(padded_docs).shape}\")\n",
    "# number of sentences, maximum sentence length, embedding feature size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49308f-4af7-4d4b-8a13-fc3bacc5f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - Get random predictions-\n",
    "# print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba44d95-8e8c-4c03-a3ea-1b45608a45e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "959c89d1-e162-458d-87ad-b60836b40a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Well done!', array([ 0,  0, 40,  7]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0], padded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a66a70e4-81d2-4738-9846-d867137ab979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237ac64-c3c2-404b-9d97-0d5b1141f019",
   "metadata": {},
   "source": [
    "#### Remember\n",
    "\n",
    "- The 3-D array has: _number of sentences, maximum sentence length, embedding feature size_. So, each sentence is represented with a 2-D array/matrix: _maximum sentence length, embedding vector size_. In this example, its (8, 20).\n",
    "\n",
    "- Each of the 4 words in ```embedded_docs[0]``` is represented with a 10-dimensional embedding vector. Therefore, ```model.predict(embedded_docs)[0]``` has the shape (4, 10).\n",
    "\n",
    "- For given ```padded_docs[0]``` example and its corresponding embedding ```model.predict(padded_docs)[0]```, the first 2 embedding vectors should be the same due to _pre-padding_ where the first 2 vectors are all 0s.\n",
    "\n",
    "- __Each word is represented using a 10-dimensional embedding vector__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0327ec-928b-475d-afb2-0290308127da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(model.predict(embedded_docs)[0][0] == model.predict(embedded_docs)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb41d9-d689-40ef-b3b6-074ee9e94945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(model.predict(embedded_docs)[0][0] == model.predict(embedded_docs)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2836d-f358-4e33-a743-79c0573150a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(model.predict(embedded_docs)[0][0] == model.predict(embedded_docs)[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2589910b-81c6-4a61-b72d-73dcbcc88711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5030433 ],\n",
       "       [0.509564  ],\n",
       "       [0.50693744],\n",
       "       [0.511469  ],\n",
       "       [0.5002052 ],\n",
       "       [0.5054037 ],\n",
       "       [0.5070193 ],\n",
       "       [0.50297856],\n",
       "       [0.50877327],\n",
       "       [0.51221883]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a2bd1-c26e-4128-af22-64af4473f936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf0543-ed56-4434-a4b2-7a54033e8c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ea48dc5-6c31-4a4e-bd86-9295670840a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.3000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.9000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6676 - accuracy: 0.8000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.7000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.9000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6076 - accuracy: 0.9000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5491 - accuracy: 0.9000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.9000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.9000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.9000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.9000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.9000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3055 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2854 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2118 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1831 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1561 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1343 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train model-\n",
    "train_history = model.fit(\n",
    "    x = padded_docs, y = labels,\n",
    "    epochs = 50, batch_size = 8,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdc41efb-cca3-4d5b-973c-18da55a6b99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained model-\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose = 0)\n",
    "print(f\"Trained accuracy = {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a83ce5-7119-4fa6-aba6-0521987f3ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709051a7-eebe-4d0f-8609-9628c78fcdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c19f4fe-18ee-414a-bf5d-ca3b77b76907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 7))\n",
    "plt.plot(train_history.history['accuracy'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.title(\"Binary classifier training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab122b-23ea-4b4d-8454-4673d72c3573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c12145-e1b8-4a1c-b16e-4355cd960cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4c16c1f-e9e0-4c7a-86f6-60bb44e962bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 50, embedding dimensionality = 10 & padded sentence input length = 4\n"
     ]
    }
   ],
   "source": [
    "# Remember from above-\n",
    "print(f\"Vocabulary size = {voc_size}, embedding dimensionality = \"\n",
    "      f\"{embedding_dim} & padded sentence input length = {max_length}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f03bf-5425-4c1a-a026-cb694342b87c",
   "metadata": {},
   "source": [
    "#### NOTE: For each of the words in the vocabulary, you have a vector of embedding dimensionality size.\n",
    "\n",
    "For the 50 words in the vocabulary, each of them are represented using a (dense) embedding vector of 10-dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d50a00-b1da-48db-b167-cfa08fad8ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "59ddc6cd-d12a-458f-80fa-075a7e701b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract trained embedding layer weights-\n",
    "model.get_weights()[0].shape\n",
    "# Or-\n",
    "# model.layers[0].embeddings.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f68551c8-b14c-412d-82d6-973c08f84735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0865592 ,  0.01758295, -0.1318761 , -0.06335241, -0.07219101,\n",
       "         0.0177235 , -0.03264572,  0.06333083,  0.03082072,  0.06642012],\n",
       "       [-0.3113638 ,  0.3509334 ,  0.20027603,  0.3017286 , -0.32910112,\n",
       "         0.29107732, -0.22193152, -0.2630986 ,  0.34740108, -0.21362609],\n",
       "       [ 0.03834507,  0.01518479,  0.02535285,  0.02351787,  0.02916468,\n",
       "         0.009999  ,  0.04440549, -0.02499225, -0.01021707,  0.04965314],\n",
       "       [ 0.02070804, -0.02125915,  0.02746493,  0.02757292,  0.03757313,\n",
       "        -0.03164186, -0.0162307 ,  0.00324904,  0.02471043, -0.01834757],\n",
       "       [ 0.0195758 , -0.00929439,  0.03243304, -0.04528047,  0.00744834,\n",
       "         0.03022804, -0.01853026, -0.01680719,  0.04527246,  0.01152835]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get trained embedding weights for first 5 words in the vocabulary-\n",
    "model.layers[0].embeddings.numpy()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af8618-29f4-4dff-a001-8fee61c11ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ce7dc-e2ee-4168-8fd6-649865bcb25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e53fef-fbf6-40c1-a231-795039480c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517af09-26dd-4a96-a998-33d88051bdce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
